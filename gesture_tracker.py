#!/usr/bin/env python3
"""
====================================================================
    RASTREADOR DE GESTOS COM MACACO
====================================================================

Descri√ß√£o:
    Sistema de reconhecimento de gestos em tempo real que detecta
    movimentos espec√≠ficos das m√£os usando a c√¢mera e exibe imagens
    de um macaco realizando o mesmo gesto.

Gestos Reconhecidos:
    1. Neutro - Posi√ß√£o padr√£o/repouso
    2. Dedo no canto da boca - Indicador pr√≥ximo ao rosto
    3. Dedo indicador para cima - Indicador apontando para cima
    4. M√£o no peito - M√£o aberta na regi√£o do peito

Tecnologias:
    - OpenCV: Captura e processamento de v√≠deo
    - MediaPipe: Detec√ß√£o e rastreamento de m√£os
    - NumPy: Opera√ß√µes matem√°ticas

Autor: Sistema de Rastreamento de Gestos
Data: 2025
====================================================================
"""

import math
# ============================================================
# IMPORTA√á√ïES
# ============================================================
import os

import cv2
import mediapipe as mp
import numpy as np


# ============================================================
# CLASSE PRINCIPAL: GestureTracker
# ============================================================
class GestureTracker:
    """
    Classe respons√°vel pelo rastreamento e reconhecimento de gestos.
    
    Atributos:
        mp_hands: M√≥dulo de detec√ß√£o de m√£os do MediaPipe
        mp_drawing: Utilit√°rios de desenho do MediaPipe
        mp_drawing_styles: Estilos de desenho do MediaPipe
        hands: Inst√¢ncia do detector de m√£os
        monkey_images: Dicion√°rio com as imagens dos gestos do macaco
        current_gesture: Gesto atualmente detectado
    """
    
    def __init__(self):
        """Inicializa o rastreador de gestos e carrega os recursos necess√°rios."""
        
        # ========================================
        # Inicializa√ß√£o do MediaPipe
        # ========================================
        self.mp_hands = mp.solutions.hands  # type: ignore
        self.mp_drawing = mp.solutions.drawing_utils  # type: ignore
        self.mp_drawing_styles = mp.solutions.drawing_styles  # type: ignore
        
        # ========================================
        # Configura√ß√£o do Detector de M√£os
        # ========================================
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,        # False = modo de v√≠deo (mais r√°pido)
            max_num_hands=2,                # Detecta at√© 2 m√£os simultaneamente
            min_detection_confidence=0.5,   # Confian√ßa m√≠nima para detec√ß√£o (0-1)
            min_tracking_confidence=0.5     # Confian√ßa m√≠nima para rastreamento (0-1)
        )
        
        # ========================================
        # Recursos do Sistema
        # ========================================
        self.monkey_images = self.load_monkey_images()  # Carrega imagens dos gestos
        self.current_gesture = "neutral"                 # Gesto inicial: neutro
        
    # ========================================
    # M√âTODO: Carregar Imagens
    # ========================================
    def load_monkey_images(self):
        """
        Carrega as imagens dos gestos do macaco da pasta 'monkey_images/'.
        
        Returns:
            dict: Dicion√°rio com {nome_do_gesto: imagem_carregada}
        """
        images = {}
        image_dir = "monkey_images"
        
        # Verificar se o diret√≥rio existe
        if not os.path.exists(image_dir):
            os.makedirs(image_dir)
            print(f"üìÅ Criado diret√≥rio {image_dir}")
            print("‚ö†Ô∏è  Adicione imagens de macacos nesta pasta:")
            print("   - neutral.png (posi√ß√£o neutra)")
            print("   - finger_mouth.png (dedo no canto da boca)")
            print("   - finger_up.png (dedo indicador para cima)")
            print("   - hand_chest.png (m√£o no peito)")
        
        # Mapeamento dos gestos e seus arquivos
        gesture_files = {
            "neutral": "neutral.png",
            "finger_mouth": "finger_mouth.png",
            "finger_up": "finger_up.png",
            "hand_chest": "hand_chest.png"
        }
        
        # Carregar cada imagem
        for gesture, filename in gesture_files.items():
            filepath = os.path.join(image_dir, filename)
            
            if os.path.exists(filepath):
                # Ler imagem (IMREAD_UNCHANGED preserva canal alpha/transpar√™ncia)
                img = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)
                
                if img is not None:
                    # Redimensionar para tamanho padr√£o (300x300 pixels)
                    img = cv2.resize(img, (300, 300))
                    images[gesture] = img
                    print(f"‚úÖ Carregada: {filename}")
                else:
                    print(f"‚ùå Erro ao ler: {filename}")
            else:
                print(f"‚ö†Ô∏è  N√£o encontrada: {filename}")
        
        return images
    
    # ========================================
    # M√âTODO: Contar Dedos Levantados
    # ========================================
    def count_fingers(self, hand_landmarks, handedness):
        """
        Conta quantos dedos est√£o levantados com base nos landmarks da m√£o.
        
        Args:
            hand_landmarks: Lista de landmarks (21 pontos) da m√£o
            handedness: "Right" ou "Left" (m√£o direita ou esquerda)
        
        Returns:
            list: Lista de 5 elementos [polegar, indicador, m√©dio, anelar, m√≠nimo]
                  onde 1 = levantado e 0 = abaixado
        
        Nota:
            O MediaPipe detecta 21 landmarks por m√£o:
            - 0: Pulso
            - 4, 8, 12, 16, 20: Pontas dos dedos
            - 3, 6, 10, 14, 18: Articula√ß√µes m√©dias
        """
        fingers_up = []
        
        # IDs dos landmarks importantes
        finger_tips = [4, 8, 12, 16, 20]    # Pontas dos 5 dedos
        finger_pips = [3, 6, 10, 14, 18]    # Articula√ß√µes para compara√ß√£o
        
        # ========================================
        # POLEGAR (l√≥gica horizontal)
        # ========================================
        # O polegar se move horizontalmente, ent√£o comparamos coordenadas X
        if handedness == "Right":
            # M√£o direita: polegar levantado = ponta mais √† esquerda que articula√ß√£o
            if hand_landmarks[finger_tips[0]].x < hand_landmarks[finger_pips[0]].x:
                fingers_up.append(1)
            else:
                fingers_up.append(0)
        else:  # Left
            # M√£o esquerda: polegar levantado = ponta mais √† direita que articula√ß√£o
            if hand_landmarks[finger_tips[0]].x > hand_landmarks[finger_pips[0]].x:
                fingers_up.append(1)
            else:
                fingers_up.append(0)
        
        # ========================================
        # OUTROS DEDOS (l√≥gica vertical)
        # ========================================
        # Os outros dedos se movem verticalmente, ent√£o comparamos coordenadas Y
        for i in range(1, 5):
            # Dedo levantado = ponta (Y menor) acima da articula√ß√£o (Y maior)
            # Nota: No OpenCV, Y cresce de cima para baixo
            if hand_landmarks[finger_tips[i]].y < hand_landmarks[finger_pips[i]].y:
                fingers_up.append(1)  # Levantado
            else:
                fingers_up.append(0)  # Abaixado
        
        return fingers_up
    
    # ========================================
    # M√âTODO: Detectar Gesto
    # ========================================
    def detect_gesture(self, hand_landmarks, handedness):
        """
        Identifica o gesto que est√° sendo realizado.
        
        Args:
            hand_landmarks: Lista de 21 landmarks da m√£o
            handedness: "Right" ou "Left"
        
        Returns:
            str: Nome do gesto detectado ("finger_mouth", "finger_up", 
                 "hand_chest", ou "neutral")
        
        L√≥gica de Detec√ß√£o:
            - Analisa quais dedos est√£o levantados
            - Calcula posi√ß√µes e dist√¢ncias entre landmarks
            - Aplica regras espec√≠ficas para cada gesto
        """
        # Obter estado dos dedos (quais est√£o levantados)
        fingers = self.count_fingers(hand_landmarks, handedness)
        fingers_count = sum(fingers)  # Total de dedos levantados
        
        # fingers = [polegar, indicador, m√©dio, anelar, m√≠nimo]
        # Exemplo: [0, 1, 0, 0, 0] = apenas indicador levantado
        
        # ========================================
        # Extrair Landmarks Importantes
        # ========================================
        wrist = hand_landmarks[0]          # Pulso (base da m√£o)
        thumb_tip = hand_landmarks[4]      # Ponta do polegar
        index_tip = hand_landmarks[8]      # Ponta do indicador
        index_pip = hand_landmarks[6]      # Articula√ß√£o do indicador
        middle_tip = hand_landmarks[12]    # Ponta do dedo m√©dio
        
        # ========================================
        # GESTO 1: Dedo no Canto da Boca
        # ========================================
        # Condi√ß√µes:
        #   - Indicador levantado
        #   - M√£o pr√≥xima ao rosto (parte superior da tela)
        #   - M√£o n√£o est√° muito esticada
        #   - Poucos dedos levantados (1 ou 2)
        
        dist_index_wrist_y = abs(index_tip.y - wrist.y)  # Dist√¢ncia vertical
        
        if (fingers[1] == 1 and                    # Indicador levantado
            index_tip.y < 0.6 and                  # Parte superior/m√©dia (Y < 0.6)
            dist_index_wrist_y < 0.4 and           # M√£o n√£o muito esticada
            fingers_count <= 2):                   # M√°ximo 2 dedos levantados
            return "finger_mouth"
        
        # ========================================
        # GESTO 2: Dedo Indicador Para Cima
        # ========================================
        # Condi√ß√µes:
        #   - Apenas indicador levantado
        #   - Indicador apontando para cima (acima do pulso)
        
        if (fingers == [0, 1, 0, 0, 0] and         # S√≥ indicador levantado
            index_tip.y < wrist.y - 0.2):          # Bem acima do pulso
            return "finger_up"
        
        # ========================================
        # GESTO 3: M√£o no Peito
        # ========================================
        # Condi√ß√µes:
        #   - M√£o na parte inferior da tela (regi√£o do peito)
        #   - M√£o centralizada horizontalmente
        #   - V√°rios dedos vis√≠veis (m√£o aberta/plana)
        
        # Calcular posi√ß√£o m√©dia/centro da m√£o
        hand_center_x = sum([hand_landmarks[i].x for i in [0, 5, 9, 13, 17]]) / 5
        hand_center_y = sum([hand_landmarks[i].y for i in [0, 5, 9, 13, 17]]) / 5
        
        chest_region_y = 0.6      # Regi√£o do peito (parte inferior, Y > 0.6)
        chest_region_x = 0.5      # Centro horizontal (X ‚âà 0.5)
        
        if (hand_center_y > chest_region_y and              # Parte inferior
            abs(hand_center_x - chest_region_x) < 0.3 and   # Pr√≥ximo ao centro
            fingers_count >= 3):                            # Pelo menos 3 dedos
            return "hand_chest"
        
        # ========================================
        # GESTO PADR√ÉO: Neutro
        # ========================================
        # Retorna se nenhum gesto espec√≠fico for detectado
        return "neutral"
    
    # ========================================
    # M√âTODO: Sobrepor Imagem
    # ========================================
    def overlay_image(self, background, overlay, x, y):
        """
        Sobrep√µe uma imagem (overlay) sobre outra (background) com suporte a transpar√™ncia.
        
        Args:
            background: Imagem de fundo (frame da c√¢mera)
            overlay: Imagem a ser sobreposta (imagem do macaco)
            x: Posi√ß√£o X (horizontal) onde colocar a imagem
            y: Posi√ß√£o Y (vertical) onde colocar a imagem
        
        Returns:
            numpy.ndarray: Imagem de fundo com overlay aplicado
        
        Nota:
            Suporta imagens PNG com canal alpha (transpar√™ncia)
        """
        if overlay is None:
            return background
        
        h, w = overlay.shape[:2]  # Altura e largura do overlay
        
        # ========================================
        # Ajustar Tamanho se N√£o Couber na Tela
        # ========================================
        if x + w > background.shape[1]:
            w = background.shape[1] - x
            overlay = cv2.resize(overlay, (w, h))
        
        if y + h > background.shape[0]:
            h = background.shape[0] - y
            overlay = cv2.resize(overlay, (w, h))
        
        # Verificar se posi√ß√£o √© v√°lida
        if x < 0 or y < 0:
            return background
        
        # ========================================
        # Aplicar Transpar√™ncia (Canal Alpha)
        # ========================================
        if overlay.shape[2] == 4:  # Imagem tem canal alpha (RGBA)
            # Normalizar alpha de 0-255 para 0-1
            alpha = overlay[:, :, 3] / 255.0
            
            # Misturar cada canal de cor (B, G, R)
            for c in range(3):
                background[y:y+h, x:x+w, c] = (
                    alpha * overlay[:, :, c] +                    # Parte vis√≠vel do overlay
                    (1 - alpha) * background[y:y+h, x:x+w, c]    # Parte vis√≠vel do fundo
                )
        else:  # Imagem sem transpar√™ncia (RGB)
            background[y:y+h, x:x+w] = overlay
        
        return background
    
    # ========================================
    # M√âTODO: Listar C√¢meras Dispon√≠veis
    # ========================================
    def list_cameras(self):
        """
        Detecta todas as c√¢meras dispon√≠veis no sistema.
        
        Returns:
            list: Lista com os √≠ndices das c√¢meras dispon√≠veis (ex: [0, 1, 2])
        
        Nota:
            Testa at√© 10 poss√≠veis c√¢meras (√≠ndices 0-9)
        """
        available_cameras = []
        print("\nüîç Procurando c√¢meras dispon√≠veis...")
        
        # Testar √≠ndices de 0 a 9
        for i in range(10):
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                available_cameras.append(i)
                cap.release()  # Liberar a c√¢mera
        
        return available_cameras
    
    # ========================================
    # M√âTODO: Selecionar C√¢mera
    # ========================================
    def select_camera(self):
        """
        Permite ao usu√°rio escolher qual c√¢mera usar.
        
        Returns:
            int: √çndice da c√¢mera selecionada (ou None se nenhuma dispon√≠vel)
        
        Comportamento:
            - Se apenas 1 c√¢mera: usa automaticamente
            - Se m√∫ltiplas c√¢meras: pede para o usu√°rio escolher
            - Se nenhuma c√¢mera: retorna None
        """
        cameras = self.list_cameras()
        
        # Nenhuma c√¢mera encontrada
        if not cameras:
            print("‚ùå Nenhuma c√¢mera encontrada!")
            return None
        
        print(f"\nüìπ C√¢meras dispon√≠veis: {cameras}")
        
        # Apenas uma c√¢mera - usar automaticamente
        if len(cameras) == 1:
            print(f"‚úÖ Usando c√¢mera {cameras[0]}")
            return cameras[0]
        
        # M√∫ltiplas c√¢meras - pedir escolha do usu√°rio
        while True:
            try:
                choice = input(f"\nEscolha a c√¢mera {cameras} (padr√£o: {cameras[0]}): ").strip()
                
                # Se usu√°rio pressionar ENTER, usar c√¢mera padr√£o
                if choice == "":
                    return cameras[0]
                
                # Validar escolha
                choice_int = int(choice)
                if choice_int in cameras:
                    return choice_int
                else:
                    print(f"‚ö†Ô∏è  C√¢mera {choice_int} n√£o est√° dispon√≠vel. Escolha entre: {cameras}")
            
            except ValueError:
                print("‚ö†Ô∏è  Por favor, digite um n√∫mero v√°lido.")
            except KeyboardInterrupt:
                print("\n\n‚ùå Opera√ß√£o cancelada pelo usu√°rio.")
                return None
    
    # ========================================
    # M√âTODO PRINCIPAL: Loop de Execu√ß√£o
    # ========================================
    def run(self, camera_id=None):
        """
        Executa o loop principal do rastreador de gestos.
        
        Args:
            camera_id: √çndice da c√¢mera a usar (None = pedir ao usu√°rio)
        
        Fluxo de Execu√ß√£o:
            1. Selecionar/abrir c√¢mera
            2. Capturar frame
            3. Detectar m√£os
            4. Reconhecer gestos
            5. Exibir resultado + imagem do macaco
            6. Repetir at√© usu√°rio pressionar 'q'
        """
        
        # ========================================
        # Inicializa√ß√£o da C√¢mera
        # ========================================
        if camera_id is None:
            camera_id = self.select_camera()
            if camera_id is None:
                return
        
        cap = cv2.VideoCapture(camera_id)
        
        if not cap.isOpened():
            print(f"‚ùå Erro: N√£o foi poss√≠vel abrir a c√¢mera {camera_id}")
            return
        
        # ========================================
        # Informa√ß√µes Iniciais
        # ========================================
        print("\n" + "=" * 60)
        print("üé• C√ÇMERA INICIADA!")
        print("=" * 60)
        print(f"üìπ Usando c√¢mera: {camera_id}")
        print("\nüëã GESTOS DISPON√çVEIS:")
        print("   ‚òùÔ∏è  Dedo indicador para cima")
        print("   üòè Dedo no canto da boca")
        print("   ü´± M√£o no peito")
        print("   üòê Neutro (sem gesto espec√≠fico)")
        print("\n‚å®Ô∏è  Pressione 'q' para sair")
        print("=" * 60 + "\n")
        
        # ========================================
        # Loop Principal
        # ========================================
        while cap.isOpened():
            # Capturar frame da c√¢mera
            success, image = cap.read()
            
            if not success:
                print("‚ö†Ô∏è  Frame vazio - ignorando...")
                continue
            
            # ========================================
            # Pr√©-processamento da Imagem
            # ========================================
            # Espelhar horizontalmente (efeito espelho mais natural)
            image = cv2.flip(image, 1)
            
            # Converter de BGR (OpenCV) para RGB (MediaPipe)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image_rgb.flags.writeable = False  # Otimiza√ß√£o de performance
            
            # ========================================
            # Detec√ß√£o de M√£os
            # ========================================
            results = self.hands.process(image_rgb)
            
            # Converter de volta para BGR
            image_rgb.flags.writeable = True
            image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
            
            # ========================================
            # Processar M√£os Detectadas
            # ========================================
            if results.multi_hand_landmarks and results.multi_handedness:
                # Iterar sobre cada m√£o detectada
                for hand_landmarks, handedness in zip(
                    results.multi_hand_landmarks, 
                    results.multi_handedness
                ):
                    # Desenhar landmarks (pontos e conex√µes) na imagem
                    self.mp_drawing.draw_landmarks(
                        image,
                        hand_landmarks,
                        self.mp_hands.HAND_CONNECTIONS,
                        self.mp_drawing_styles.get_default_hand_landmarks_style(),
                        self.mp_drawing_styles.get_default_hand_connections_style()
                    )
                    
                    # Detectar o gesto
                    hand_label = handedness.classification[0].label  # "Left" ou "Right"
                    gesture = self.detect_gesture(hand_landmarks.landmark, hand_label)
                    self.current_gesture = gesture
                    
                    # Exibir nome do gesto na tela
                    cv2.putText(
                        image,
                        f"Gesto: {gesture}",
                        (10, 30),                      # Posi√ß√£o (x, y)
                        cv2.FONT_HERSHEY_SIMPLEX,      # Fonte
                        1,                              # Tamanho
                        (0, 255, 0),                   # Cor verde (BGR)
                        2                               # Espessura
                    )
            else:
                # Nenhuma m√£o detectada - gesto neutro
                self.current_gesture = "neutral"
            
            # ========================================
            # Exibir Imagem do Macaco
            # ========================================
            if self.current_gesture in self.monkey_images:
                monkey_img = self.monkey_images[self.current_gesture]
                
                # Posicionar no canto superior direito
                x_offset = image.shape[1] - 320  # 20px de margem
                y_offset = 10                     # 10px do topo
                
                image = self.overlay_image(image, monkey_img, x_offset, y_offset)
            
            # ========================================
            # Exibir Frame
            # ========================================
            cv2.imshow('Rastreador de Gestos com Macaco üêí', image)
            
            # ========================================
            # Verificar Tecla Pressionada
            # ========================================
            if cv2.waitKey(5) & 0xFF == ord('q'):
                print("\nüëã Saindo...")
                break
        
        # ========================================
        # Limpeza e Encerramento
        # ========================================
        cap.release()
        cv2.destroyAllWindows()
        print("‚úÖ Programa encerrado com sucesso!")
        print("=" * 60 + "\n")

# ============================================================
# FUN√á√ÉO PRINCIPAL
# ============================================================
def main():
    """
    Ponto de entrada do programa.
    
    Fun√ß√£o:
        - Exibe banner inicial
        - Cria inst√¢ncia do rastreador
        - Inicia o loop de detec√ß√£o
    """
    # Banner de boas-vindas
    print("\n" + "=" * 60)
    print("üêí RASTREADOR DE GESTOS COM MACACO üêí")
    print("=" * 60)
    print("Sistema de reconhecimento de gestos em tempo real")
    print("Desenvolvido com OpenCV e MediaPipe")
    print("=" * 60)
    
    try:
        # Criar e executar o rastreador
        tracker = GestureTracker()
        tracker.run()
    
    except KeyboardInterrupt:
        print("\n\n‚ùå Programa interrompido pelo usu√°rio (Ctrl+C)")
        print("=" * 60 + "\n")
    
    except Exception as e:
        print(f"\n\n‚ùå Erro inesperado: {e}")
        print("=" * 60 + "\n")
        raise


# ============================================================
# EXECU√á√ÉO DO PROGRAMA
# ============================================================
if __name__ == "__main__":
    main()
    main()
